{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb9959a-28ac-43bc-8b5f-a9ced2b54f65",
   "metadata": {},
   "source": [
    "# Machine learning on pulse fit parameters\n",
    "\n",
    "This notebook demonstrates the functions in `fastepy` to perform machine learning on the pulse best-fit parameters in order to separate signal from __intrinsic__ background. The functionality relies mostly in `sklearn`.\n",
    "\n",
    "We start with the relevant imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "573b73b5-3f16-40ee-8e24-5cefc1e39975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "from pathlib import PosixPath\n",
    "from fastespy.io.readpydata import convert_data_to_ML_format, load_data_rikhav\n",
    "from fastespy.mlscikit import hyperpartune\n",
    "from fastespy.utils import init_logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e89516-b17c-4408-b451-35d91f9d9f5a",
   "metadata": {},
   "source": [
    "Now we define some parameters of the analysis, e.g., where we save the data, where we want to put the output files (for plotting them later), and which classifier we want to use. \n",
    "\n",
    "The following classifiers from `sklearn` are currently implemented:\n",
    "\n",
    "- `dt`: Decision trees. This is mostly for testing as the training is fast. \n",
    "- `bdt`: Boosted descision trees.\n",
    "- `rf`: Random forests\n",
    "- `mlp`: multi-layer perceptron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d0dc4ac-9451-4cd2-aa91-8570c6f068ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/manuelmeyer/Documents/TESData/ml_results_clf-dt_log-data1_pca1/\n"
     ]
    }
   ],
   "source": [
    "# input directory with data\n",
    "indir = \"/Users/manuelmeyer/Documents/TESData/August2020/\"   # August 2020 data\n",
    "\n",
    "# classifier with naming scheme as above\n",
    "classifier_name = 'dt'\n",
    "\n",
    "# number of cores to use\n",
    "n_jobs = 8\n",
    "\n",
    "# random seed for the analysis \n",
    "random_state = 42\n",
    "\n",
    "# Use a coarse grid for the hyper parameter search?\n",
    "coarse_grid = True\n",
    "\n",
    "# Use class weights in hyper parameter optimization?\n",
    "class_weight_grid = False\n",
    "\n",
    "# log transform the data?\n",
    "log_data = True\n",
    "\n",
    "# Use PCA to transform data?\n",
    "use_pca = True\n",
    "\n",
    "# The number of k-folds for inner and outer loop\n",
    "kfolds = 5\n",
    "\n",
    "# output directory for ML results\n",
    "outdir = f\"/Users/manuelmeyer/Documents/TESData/ml_results_clf-{classifier_name}_log-data{log_data:n}_pca{use_pca:n}/\"\n",
    "print(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8306ed7-cbd5-48b1-9e35-8ef1913d1cc2",
   "metadata": {},
   "source": [
    "Instead of running the rest of the notebook, you could also run the analysis on the command line by executing the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e9dcf42-ce3e-4eb9-8e67-80e749a2bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run ../fastespy/scripts/scikit_hyperpartuning.py -i $indir -o $outdir -c $classifier_name --n_jobs $n_jobs \n",
    "# --random_state $random-state --coarse_grid $coarse_grid --class-weight-grid $class_weight_grid --log-data $log_data --use-pca $use_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac89dc2-db96-4915-a151-006b5211c1fb",
   "metadata": {},
   "source": [
    "Initialize nice colorful logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a8b3f3d-0372-4556-a5bc-987b1b290422",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_logging(\"INFO\", color=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea173f-ac69-4960-b2e0-a3a5eec41cab",
   "metadata": {},
   "source": [
    "Get the input files and set up output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9785f5d4-5877-4206-b18b-ed3c5335d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = PosixPath(indir)\n",
    "out_dir = PosixPath(outdir)\n",
    "\n",
    "if not out_dir.exists():\n",
    "    out_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc0e70-76d9-4ac2-b3e1-c40cb5e96756",
   "metadata": {},
   "source": [
    "Get a list of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8333f647-9ca8-4a77-9cb2-e0007dbd9094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m1735487905.py:\u001b[0;35m   3\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: Using files:\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GHzGBWP-intrinsics-50MHz-20mV-1day-16-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GHzGBWP-intrinsics-50MHz-20mV-72hrs-3-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GHz-light-000-fit.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GBWP-intrinsics-50MHz-20mV-1day-9-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GHzGBWP-intrinsics-50MHz-20mV-1day-13-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GHzGBWP-intrinsics-50MHz-20mV-1day-14-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GHzGBWP-intrinsics-50MHz-20mV-72hrs-1-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GBWP-intrinsics-50MHz-20mV-1day-6-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GHzGBWP-intrinsics-50MHz-20mV-1day-11-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GBWP-intrinsics-50MHz-20mV-1day-8-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GHzGBWP-intrinsics-50MHz-20mV-1day-12-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GHzGBWP-intrinsics-50MHz-20mV-72hr-2-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GHzGBWP-intrinsics-50MHz-20mV-1day-17-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GBWP-intrinsics-50MHz-20mV-1day-7-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GHzGBWP-intrinsics-50MHz-20mV-1day-10-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GHzGBWP-intrinsics-50MHz-20mV-1day-15-fit000.npy\n",
      "\u001b[0;36m1735487905.py:\u001b[0;35m   5\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: /Users/manuelmeyer/Documents/TESData/August2020/0.3RN-1.5GHzGBWP-intrinsics-50MHz-20mV-1day-18-fit000.npy\n"
     ]
    }
   ],
   "source": [
    "files = list(in_dir.glob(\"*.npy\"))\n",
    "\n",
    "logging.info(\"Using files:\")\n",
    "for f in files:\n",
    "    logging.info(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57f41b2-66f8-4450-a289-af48a6ee0cc5",
   "metadata": {},
   "source": [
    "Next, we define the names of the features we would like to use. These are of course specific to the formatting of the output files. I will here assume the file formats used in Rikhav's analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f546ff90-697d-45b1-94fa-5efaef4c243d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m2405857269.py:\u001b[0;35m  17\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: Using features names ['rise time', 'decay time', 'constant', 'amplitude', 'pulse height', 'chi2 reduced', 'pulse integral fit']\n"
     ]
    }
   ],
   "source": [
    "# define the feature names\n",
    "feature_names = []\n",
    "\n",
    "# these names will be removed\n",
    "remove = ['data', 'time', 'pulse integral raw', 'voltage error',\n",
    "          'error', 'start time in hrs', 'end time in hrs',\n",
    "          'trigger time'\n",
    "          ]\n",
    "\n",
    "# read in one file to get the feature names\n",
    "# and remove those you don't want\n",
    "x = np.load(files[0], allow_pickle=True).tolist()\n",
    "for k in x[1].keys():\n",
    "    if not k in remove and not 'error' in k:\n",
    "        feature_names.append(k)\n",
    "\n",
    "logging.info(\"Using features names {}\".format(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b72ba06-7dd1-4203-bd08-fb8dee924bf7",
   "metadata": {},
   "source": [
    "We now define some minimal data cleaning cuts: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62018d3b-cf43-43c8-b012-d1c205738679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m838698770.py:\u001b[0;35m   7\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: Using cleaning cuts {'chi2 reduced': 'chi2 < 6.', 'decay time': 'decay < 10.e-6', 'trigger time': '(trigger >= 29.5e-6) & (trigger <= 30.8e-6)'}\n"
     ]
    }
   ],
   "source": [
    "# define light cleaning cuts\n",
    "light_cleaning_cuts = {\n",
    "    \"chi2 reduced\": \"chi2 < 6.\",\n",
    "    \"decay time\": \"decay < 10.e-6\",\n",
    "    \"trigger time\": \"(trigger >= 29.5e-6) & (trigger <= 30.8e-6)\",  # from gaussian fit, 5 sigma interval\n",
    "}\n",
    "logging.info(\"Using cleaning cuts {}\".format(light_cleaning_cuts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702222aa-8c97-4f5c-b785-64aa439a54ed",
   "metadata": {},
   "source": [
    "Next we read the output from Rikhav's fits. The `result` dict contains the best fit parameters. The `data` dict contains the raw time lines. \n",
    "The `t_tot_hrs` gives the total time of the data run in hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b227ebc5-1196-493c-8039-da643a181272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;36mreadpydata.py:\u001b[0;35m 291\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: Reading data\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  3.44it/s]\n",
      "\u001b[0;36mreadpydata.py:\u001b[0;35m 339\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: Rejected 1561 triggers in light file\n",
      "\u001b[0;36mreadpydata.py:\u001b[0;35m 350\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: In total, there are 1066 light events and 39580 background events for an observation time of 517.91 hours\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['type', 'rise time', 'decay time', 'constant', 'amplitude', 'pulse height', 'chi2 reduced', 'pulse integral fit'])\n",
      "dict_keys(['time', 'data'])\n",
      "517.906026640339\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "result, data, t_tot_hrs = load_data_rikhav(files, feature_names, light_cleaning_cuts=light_cleaning_cuts)\n",
    "\n",
    "print (result.keys())\n",
    "print (data.keys())\n",
    "print (t_tot_hrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc8c26a-1cf9-4b0a-ac6e-07eac2a68198",
   "metadata": {},
   "source": [
    "The data needs to be converted into the standard `sklearn` format: `X` is an array with shape `[n_samples, n_features]` and `y` contains the class labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc1162f1-1824-4084-b9a0-02d50c7890b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40646, 7)\n",
      "(40646,)\n"
     ]
    }
   ],
   "source": [
    "X, y = convert_data_to_ML_format(result,\n",
    "                                 feature_names,\n",
    "                                 bkg_type=0,  # this specifies which result['type'] corresponds to background\n",
    "                                 signal_type=1  # this specifies which result['type'] corresponds to signal\n",
    "                                )\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805d13a-ddc1-4c43-83f3-3dbec539e360",
   "metadata": {},
   "source": [
    "Lastly, we set up the default parameters and the hyper-parameter grid. Every combination of the hyper-parameter grid will be tested. These grids are pre-defined but you could also define your own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "441186f2-edb0-4a89-b05d-1f2f323abc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'min_samples_leaf': 1}\n",
      "{'ccp_alpha': array([0.     , 0.00025, 0.0005 , 0.00075, 0.001  ]), 'min_samples_split': array([ 2, 12, 22, 32, 42, 52]), 'max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "       19, 20])}\n"
     ]
    }
   ],
   "source": [
    "# default parameters\n",
    "default_pars = hyperpartune.default_pars[classifier_name]\n",
    "print(default_pars)\n",
    "\n",
    "# parameter grid\n",
    "if coarse_grid:\n",
    "    param_grid = hyperpartune.param_grid_coarse[classifier_name]\n",
    "else:\n",
    "    param_grid = hyperpartune.param_grid[classifier_name]\n",
    "print(param_grid)\n",
    "\n",
    "# the classifier\n",
    "classifier = hyperpartune.clf[classifier_name](random_state=random_state,\n",
    "                                               **default_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37206dae-28ad-442b-ac48-c199d71ec834",
   "metadata": {},
   "source": [
    "This last step will run the hyper-parameter optimization for `kfolds x kfolds` iterations. The results will be written to an `npy` file in the output directory. We will look at the results in another notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d74bc75-a0d8-453b-a9d1-3aa9211f6dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;36mhyperpartune.py:\u001b[0;35m1098\u001b[0;0m --- \u001b[1;36m\u001b[1;36mINFO\u001b[1;0m\u001b[1;0m: Transforming data to log space\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded 40646 triggers in log transform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelmeyer/Python/fastespy/fastespy/mlscikit/hyperpartune.py:408: RuntimeWarning: invalid value encountered in log10\n",
      "  X[:, j] = np.log10(X[:, j])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4h/qfkd75ns1vzg60n7w4jchlw40000gr/T/ipykernel_54575/2656407515.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m hyperpartune.run_hyper_par_opt_all_folds(X, y,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                          \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                          \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                          \u001b[0mdefault_pars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_pars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/fastespy/fastespy/mlscikit/hyperpartune.py\u001b[0m in \u001b[0;36mrun_hyper_par_opt_all_folds\u001b[0;34m(X, y, feature_names, classifier, param_grid, default_pars, t_tot_hrs, data, kfolds, classifier_name, out_dir, random_state, log_data, use_pca, n_jobs)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0mname\u001b[0m \u001b[0mof\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0mout_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPosixPath\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mThe\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mseed\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/miniforge3/envs/ml/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \"\"\"\n\u001b[0;32m--> 731\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/miniforge3/envs/ml/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/miniforge3/envs/ml/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001b[0m\u001b[1;32m    727\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "hyperpartune.run_hyper_par_opt_all_folds(X, y,\n",
    "                                         feature_names=feature_names,\n",
    "                                         classifier=classifier,\n",
    "                                         default_pars=default_pars,\n",
    "                                         param_grid=param_grid,\n",
    "                                         t_tot_hrs=t_tot_hrs,\n",
    "                                         data=data,\n",
    "                                         kfolds=kfolds,\n",
    "                                         classifier_name=classifier_name,\n",
    "                                         random_state=random_state,\n",
    "                                         log_data=log_data,\n",
    "                                         use_pca=use_pca,\n",
    "                                         out_dir=out_dir,\n",
    "                                         n_jobs=n_jobs)\n",
    "\n",
    "print(\"It took {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff33ad4-fca2-461c-a97e-eefa651ab202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
